{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Computer science","text":""},{"location":"machine-learning/intro/","title":"Introduction to Machine Learning","text":"<p>Machine Learning is a rapidly growing field in computer science that focuses on the development of algorithms and models that can learn from and make predictions on data. In this lecture, we will cover the basics of machine learning, including its applications, types of learning, and common algorithms.</p>"},{"location":"machine-learning/intro/#what-is-machine-learning","title":"What is Machine Learning?","text":"<p>Machine Learning (ML) is a subset of Artificial Intelligence (AI) that deals with the ability of a system to learn from data and improve its performance over time. The main goal of ML is to create models that can automatically learn patterns and relationships from data without being explicitly programmed.</p> <p></p>"},{"location":"machine-learning/intro/#and-what-about-deep-learning","title":"And what about Deep Learning ?","text":"<p>Deep learning is a subfield of Machine learning (when you heard about Neural network, it involves deep learning) one key difference between machine learning and deep learning is the level of abstraction involved in the feature  extraction process. In machine learning, features are typically manually extracted from the data and then used as inputs to the model. In deep learning, the model learns to extract the relevant features automatically,  as part of the training process.</p> <p>Question</p> <p>What is feature extraction ? </p> <p>Feature extraction is the process of selecting and transforming raw data into a set of features that can be used to  represent the data in a more meaningful way for a machine learning model. In machine learning, features are  essentially the measurable properties of the data that are used to make predictions or decisions.</p> <p></p>"},{"location":"machine-learning/intro/#why-it-became-so-popular-only-around-2010","title":"Why it became so popular only around 2010?","text":"<p>Machine learning has been around since the mid-20th century, but it wasn't until around 2010 that it became widely  popular. There are several reasons why this happened:</p> <ul> <li> <p>Big Data: The explosion of digital data in the 21st century has made it possible to train and test machine learning  models on massive amounts of data. This has made it easier to develop accurate models that can handle complex tasks.</p> </li> <li> <p>Advances in computing power: The development of powerful computers and the availability of cloud computing resources  have made it possible to process and analyze large amounts of data quickly and efficiently.</p> </li> <li> <p>Open-source software: The availability of open-source software frameworks like TensorFlow, PyTorch, and Scikit-learn  has made it easier for developers to experiment with machine learning algorithms and develop applications.</p> </li> <li> <p>Increased awareness: The growth of social media and the internet has led to increased awareness of the potential  applications of machine learning, and its ability to solve complex problems.</p> </li> </ul>"},{"location":"machine-learning/intro/#example-applications-of-machine-learning","title":"Example applications of Machine Learning","text":"<p>Machine Learning is being used in various applications across different industries. Some of the popular applications include:</p> <ul> <li>Image and Speech Recognition</li> <li>Natural Language Processing</li> <li>Fraud Detection</li> <li>Recommender Systems</li> <li>Predictive Maintenance</li> <li>Autonomous Vehicles</li> </ul>"},{"location":"machine-learning/intro/#types-of-machine-learning","title":"Types of Machine Learning","text":"<p>There are three main types of Machine Learning : </p>"},{"location":"machine-learning/intro/#supervised-learning","title":"Supervised Learning","text":"<p>In supervised learning, the model is trained on labeled data (input-output pairs). The goal is to learn a mapping function that can predict the output for new input data. Popular algorithms include Linear Regression, Logistic Regression, Decision Trees, Random Forests, and Neural Networks.</p>"},{"location":"machine-learning/intro/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>In unsupervised learning, the model is trained on unlabeled data. The goal is to learn the underlying structure of the data and identify patterns and relationships. Popular algorithms include Clustering, Principal Component Analysis (PCA), and Association Rule Learning.</p>"},{"location":"machine-learning/intro/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>In reinforcement learning, the model learns by interacting with the environment and receiving feedback in the form of rewards or punishments. The goal is to learn a policy that maximizes the cumulative reward over time. Popular algorithms include Q-Learning, SARSA, and Deep Reinforcement Learning.</p> <pre><code>\n    graph LR\n    A[Machine Learning] --&gt; B[Supervised Learning]\n    A --&gt; C[Unsupervised Learning]\n    A --&gt; D[Reinforcement Learning]\n    B --&gt; E[Regression]\n    B --&gt; F[Classification]\n    C --&gt; G[Clustering]\n    C --&gt; H[Dimensionality Reduction]\n</code></pre>"},{"location":"machine-learning/intro/#some-examples-foreach-category","title":"Some examples foreach category","text":""},{"location":"machine-learning/intro/#supervised-learning_1","title":"Supervised Learning:","text":"<p>Here are some examples of applications of supervised learning:</p> <ul> <li>Spam detection: In email filtering, the algorithm is trained on labeled data to classify emails as spam or not spam. </li> <li>Image recognition: In image classification, the algorithm is trained on labeled images to identify objects within images, such as people or animals. </li> </ul> <p>Data labeling information</p> <p>Maybe you know it, but when you're doing a captcha... you're labelling image</p> <p></p> <p>Facebook's photo tagging system is one example of how the company uses machine learning to identify faces in photos  and suggest tags to users. When users tag their friends in photos, it helps Facebook's algorithms learn and improve  their ability to identify faces and make more accurate suggestions in the future.</p> <p>Similarly, Twitter uses hashtags to train their algorithms. When users include hashtags in their tweets,  it helps Twitter's machine learning algorithms understand the context and topics being discussed.  This enables Twitter to make better recommendations to users about who to follow, what content to engage with,  and which ads to display.</p> <p></p> <ul> <li>Object detection is a computer vision task that involves identifying and localizing objects within an image or video. It is a more complex task than image classification because it not only requires identifying what objects are present in an image, but also where they are located within the image. Object detection algorithms are typically trained on labeled images that provide both the class label  (e.g. \"person\", \"car\", \"tree\", etc.) and the bounding box coordinates of each object in the image. </li> </ul> <p></p> <ul> <li>Fraud detection: In financial fraud detection, the algorithm is trained on labeled data to identify fraudulent transactions.</li> </ul>"},{"location":"machine-learning/intro/#unsupervised-learning_1","title":"Unsupervised Learning:","text":"<p>Here are some examples of applications of unsupervised learning:</p> <ul> <li>Customer segmentation: In marketing, unsupervised learning can be used to segment customers into groups based on similar behavior or characteristics.</li> <li>Anomaly detection: In cybersecurity, unsupervised learning can be used to identify unusual network activity or behavior that may be indicative of a security breach.</li> <li>Topic modeling: In natural language processing, unsupervised learning can be used to identify topics within a corpus of text documents.</li> </ul>"},{"location":"machine-learning/intro/#reinforcement-learning_1","title":"Reinforcement Learning:","text":"<p>Here are some examples of applications of reinforcement learning:</p> <ul> <li>Game playing: Reinforcement learning has been used to develop game-playing agents that can beat human experts at games such as chess and Go.</li> <li>Robotics: Reinforcement learning can be used to train robots to perform tasks such as grasping and manipulation of objects.</li> <li>Autonomous driving: Reinforcement learning can be used to train self-driving cars to navigate complex traffic scenarios.</li> </ul>"},{"location":"machine-learning/intro/#common-machine-learning-algorithms","title":"Common Machine Learning Algorithms","text":"<p>There are various algorithms used in Machine Learning, some of which include:</p> Algorithm Category Linear Regression Supervised Learning Logistic Regression Supervised Learning Decision Trees Supervised Learning Random Forest Supervised Learning Support Vector Machines (SVM) Supervised Learning k-Nearest Neighbors (k-NN) Supervised Learning Naive Bayes Supervised Learning K-Means Unsupervised Learning Hierarchical Clustering Unsupervised Learning Principal Component Analysis (PCA) Unsupervised Learning Apriori Unsupervised Learning QLearning Reinforcement Learning <p>Note</p> <p>This list contains only some of the common algorithm you'll met</p>"},{"location":"machine-learning/intro/#some-history","title":"Some history","text":""},{"location":"machine-learning/intro/#conclusion","title":"Conclusion","text":"<p>In conclusion, Machine Learning is an exciting field that has numerous applications and is rapidly growing. In this lecture, we have covered the basics of Machine Learning, including its applications, types of learning, and common algorithms. In the following lectures, we will dive deeper into each of these topics and learn how to apply them in real-world scenarios.</p>"},{"location":"machine-learning/linear-regression/","title":"Linear regression","text":""},{"location":"machine-learning/linear-regression/#simple-linear-regression","title":"Simple linear regression","text":"<p>What is a simple linear regression?</p> <p>Simple linear regression is a statistical method used to model the relationship between two variables,  where one variable (the independent variable) is used to predict the other variable (the dependent variable).  The goal of simple linear regression is to find a line of best fit that summarizes the relationship between the two  variables. In other words, we want to find the equation of a line that comes as close as possible to passing through  all of the data points in the scatter plot of the two variables.</p>"},{"location":"machine-learning/linear-regression/#lets-start-by-an-example","title":"Let's start by an example","text":""},{"location":"machine-learning/linear-regression/#input-data","title":"Input data","text":"<p>Assuming we have a dataset which represents the given tips depending on the amount of the bill</p> <p>Info</p> <p>We already know some data</p> <p></p> <p>Info</p> <p>From this data, we can find <code>y = mx + b</code> that \"best fit\" the points</p> <p></p> <p>Info</p> <p>Now we can predict <code>tips_amount</code> given <code>total_bill</code></p> <p></p> <p>The equation for a straight line is given by:</p> \\[ {y = mx + b} \\] <p>Where :</p> <ul> <li>y is the dependent variable </li> <li>x is the independent variable</li> <li>m is the slope of the line</li> <li>b is the y-intercept (i.e., the value of y when x is zero).</li> </ul> <p>How to find the values of m and b?</p> <p>In simple linear regression, we use the method of least squares to find the values of <code>m</code> and <code>b</code> that minimize the  sum of the squared differences between the observed values of <code>y</code> and the predicted values of <code>y</code>  (i.e., the values of y predicted by the line of best fit).</p> <p>The least squares method involves the following steps:</p> <ul> <li>Compute the mean of the independent variable x and the mean of the dependent variable y.</li> <li> <p>Compute the slope of the line of best fit m using the formula: </p> <p><code>m = sum((xi - x_mean) * (yi - y_mean)) / sum((xi - x_mean)^2)</code></p> <p>Where : </p> <ul> <li>xi and yi are the values of the independent and dependent variables, respectively </li> <li>x_mean and y_mean are their respective means.</li> </ul> </li> </ul> <p></p> <ul> <li> <p>Compute the y-intercept b using the formula:</p> <p><code>b = y_mean - m * x_mean</code></p> </li> </ul> <p>Once we have computed the values of m and b, we can use the equation <code>y = mx + b</code> to predict the value of y for any  given value of x.</p> <p>In the case of multiple linear regression, where there are multiple independent variables, the computation is a bit more complicated, but the basic idea is the same: we want to find the equation of a hyperplane that comes as close as  possible to passing through all of the data points in the scatter plot of the independent and dependent variables.  The method of least squares is also used to find the values of the coefficients (i.e., the slopes) of the hyperplane  that minimize the sum of the squared differences between the observed values of y and the predicted values of y.</p>"},{"location":"machine-learning/linear-regression/#implementation-example-with-sklearn","title":"Implementation example with Sklearn","text":""},{"location":"machine-learning/logistic-regression/","title":"Logistic regression","text":"<p>What is a logistic regression</p> <p>Logistic regression is a statistical method used for modeling the relationship between a binary dependent variable  (also known as the response or outcome variable) and one or more independent variables (also known as predictors  or explanatory variables). The goal of logistic regression is to predict the probability of the binary outcome  based on the values of the predictors.</p> <p>The dependent variable in logistic regression is typically binary (e.g., yes/no, 1/0, success/failure), although it can also be ordinal or nominal. The independent variables can be continuous, categorical, or a combination of both.</p> <p>The logistic regression model estimates the log odds (logit) of the binary outcome as a linear combination of the independent variables. The logit is then transformed into a probability using the logistic function, which produces a value between 0 and 1. This probability represents the predicted likelihood of the binary outcome given the values of the independent variables.</p> <p>Logistic regression is often used in classification tasks, such as predicting whether a customer will churn or not, whether an email is spam or not, or whether a patient will respond to a particular treatment or not. It can also be used for understanding the relationship between variables and exploring the effects of different factors on the binary outcome.</p> <p>The math behind</p> <p>The mathematical foundation of logistic regression is based on the logistic function, which is a type of sigmoid  function. The logistic function is defined as:</p> \\[f(z) = 1 / (1 + e^-z)\\] <p>where z is the linear combination of the independent variables and their associated coefficients, or weights. In other words, z = b0 + b1x1 + b2x2 + ... + bpxp, where b0 is the intercept or constant term and b1 to bp are the coefficients for the independent variables x1 to xp.</p>"},{"location":"machine-learning/logistic-regression/#the-iris-dataset-example","title":"The iris dataset example","text":"<p>The iris dataset is often used for educational purpose in machine learning.  It contains the following informations : </p> Column Description sepal_length Length of sepal (in centimeters) sepal_width Width of sepal (in centimeters) petal_length Length of petal (in centimeters) petal_width Width of petal (in centimeters) species The species of iris (Setosa, Versicolor, or Virginica) <p>Objective</p> <p>Given the four feature sepal_length, sepal_width, petal_length, petal_width, we want to build a model which is able  to predict the class (which species) based on new samples -&gt; It's a multi class classification problem</p>"},{"location":"machine-learning/logistic-regression/#lets-deep-dive-a-bit-in-the-data","title":"Let's deep dive a bit in the data","text":"<p>Info</p> <p>The example we will use contains 150 samples</p> <p></p>"},{"location":"machine-learning/logistic-regression/#now-lets-solve-this-classification-problem-with-the-logistic-regression","title":"Now let's solve this classification problem with the Logistic Regression","text":""},{"location":"machine-learning/model-evaluation/","title":"Model evaluation","text":""},{"location":"machine-learning/model-evaluation/#splitting-our-data-for-training-testing-and-validation","title":"Splitting our data for training, testing, and validation","text":"<p>Info</p> <p>Train-test-validation is a common approach used in machine learning to evaluate the performance of a model.  The approach involves dividing a dataset into three parts: a training set, a validation set, and a test set.</p>"},{"location":"machine-learning/model-evaluation/#the-training-set","title":"The training set","text":"<p>It is the portion of the dataset used to train the model. The model learns from the patterns and  relationships present in the training data and uses this knowledge to make predictions on new, unseen data.</p>"},{"location":"machine-learning/model-evaluation/#the-validation-set","title":"The validation set","text":"<p>It is used to evaluate the performance of the model during training.  As the model learns from the training data, its performance is evaluated on the validation set to assess whether  it is overfitting (i.e., memorizing the training data and performing poorly on new data) or underfitting  (i.e., not capturing the patterns and relationships present in the training data).</p>"},{"location":"machine-learning/model-evaluation/#the-test-set","title":"The test set","text":"<p>Tips</p> <p>You can think about the test set as <code>unseen data</code></p> <p>It is used to evaluate the performance of the model after it has been trained and tuned on the training and  validation sets. The test set provides an unbiased estimate of the model's performance on new, unseen data.</p> <p>The train-test-validation approach is important because it enables us to assess the quality of the model's predictions and make informed decisions about how to improve the model. By dividing the dataset into separate training, validation, and test sets, we can ensure that the model is not overfitting or underfitting and that it can generalize well to new, unseen data.</p>"},{"location":"machine-learning/model-evaluation/#classification","title":"Classification","text":"<p>Tips</p> <p>In general we use a confusion matrix to visualize the error made by an algorithm in a classification problem it's not limited to binary classification.</p> Actual Positive Actual Negative Predicted Positive TP FP Predicted Negative FN TN Evaluation Metric Formula When to Use Accuracy (TP + TN) / (TP + TN + FP + FN) Balanced Precision TP / (TP + FP) Imbalanced Recall TP / (TP + FN) Imbalanced F1 Score 2 * (Precision * Recall) / (Precision + Recall) Imbalanced"},{"location":"machine-learning/model-evaluation/#regression","title":"Regression","text":"Evaluation Metric Formula When to Use Mean Squared Error (MSE) 1/n * \u2211(y_true - y_pred)^2 General Root Mean Squared Error (RMSE) \u221a(1/n * \u2211(y_true - y_pred)^2) General R-squared (R2) 1 - \u2211(y_true - y_pred)^2 / \u2211(y_true - y_true_mean)^2 General MAE (Mean Absolute Error) 1/n * \u2211                        (      y_true - y_pred ) General MAPE (Mean Absolute Percentage Error) 100% * 1/n * \u2211( y_true - y_pred) / y_true Specific"},{"location":"machine-learning/prerequisites/","title":"Before developing","text":"<p>Warning</p> <p>Before creating a machine learning algorithm, there are several steps that should be taken to ensure that the  problem is well-defined, the data is appropriate and that the algorithm can be effectively trained</p>"},{"location":"machine-learning/prerequisites/#1-define-the-problem","title":"1 - Define the problem","text":"<p>Start by defining the problem you want to solve, the objectives. </p> <ul> <li>What is the goal of your algorithm? </li> <li>What kind of data will you be working with?</li> <li>What performance are we expecting ?</li> <li>Do I have data ? </li> </ul>"},{"location":"machine-learning/prerequisites/#2-collect-the-data-the-right-data","title":"2 - Collect the data... The right data","text":"<p>Gather the data you will need to train and test your algorithm. This might involve:</p> <ul> <li>scraping data from the web</li> <li>collecting data from sensors</li> <li>working with pre-existing data sets</li> </ul> <p>Danger</p> <p>In real-life application, the data itself is one thing on which you need to spend time :  </p> <ul> <li>You need to ensure that the data describe your real-life problem </li> <li>You need to ensure that its quality is good</li> <li>Are you able to produce the data you will use to train your model It doesn't make sense to have an algorithm that work well in laboratory condition, if you need to use it in  different condition</li> </ul> <p>Let's take an example :</p> <p>Example</p>"},{"location":"machine-learning/prerequisites/#assuming-you-want-to-train-a-classification-model-to-classify-eyes-diseases-with-a-camera-embedded-on-a-raspberry","title":"Assuming you want to train a classification model to classify eyes diseases, with a camera embedded on a raspberry.","text":"<p>After some research on google, you'll find some already labeled dataset like this :</p> <p></p> <p> </p> <p>But with your camera, you're only able to produce image like this : </p> <p></p> <p>It's completly out of scope, it doesn't make sense to train the algorithm on this dataset</p>"},{"location":"machine-learning/prerequisites/#what-can-i-do","title":"What can i do ?","text":"<p>You have mainly two solutions : </p> <ul> <li>Take some pictures of eyes with diseases you want to classify</li> <li>Scrap some data on internet and label it yourself</li> </ul>"},{"location":"machine-learning/prerequisites/#3-explore-the-data","title":"3 - Explore the data","text":"<p>Once you have your data, explore it to get a better understanding of what you're working with.  This might involve data visualization and basic statistical analysis.</p> <p>See an example</p>"},{"location":"machine-learning/prerequisites/#4-preprocess-the-data","title":"4 - Preprocess the data","text":"<p>Preprocessing the data involves transforming and cleaning the data so that it can be used by the machine learning  algorithm. This might involve feature engineering, data scaling, data normalization, data augmentation and data  cleaning.</p> What is data normalization ? <p>Data normalization is the process of rescaling the values of numeric features in a dataset to a common scale.  This is typically done to prevent features with large values from dominating the analysis and to ensure that all  features have equal weight. One common technique for normalization is called <code>min-max scaling</code>  which involves scaling the values of a feature to a range between 0 and 1 by subtracting the minimum value of the  feature and dividing by the range of the feature.</p> What is data scaling ? <p>Data scaling is a similar technique to normalization that involves transforming the values of numeric features  so that they have a mean of 0 and a standard deviation of 1. This is typically done to ensure that all features  have the same variance and that the data is centered around 0. One common technique for scaling is called  \"standardization,\" which involves subtracting the mean of the feature and dividing by its standard deviation.</p> What is data augmentation ? <p>Data augmentation is a technique used to increase the size of a training dataset by creating new, <code>synthetic</code> data points through transformations of existing data. The goal of data augmentation is to improve the  performance and generalization of machine learning models by exposing them to a wider range of variations in the data.</p> <p>Data augmentation can be applied to a wide range of data types, including images, audio, and text. For example, in image data augmentation, you can create new images by applying transformations such as rotation, translation, scaling,  flipping, and cropping to existing images. In audio data augmentation, you can apply transformations such as changing the pitch, tempo, or volume of existing audio recordings. In text data augmentation, you can create new text samples by replacing words with synonyms.</p> <p>Data augmentation is particularly useful in scenarios where the amount of available training data is limited. By creating new data points through data augmentation, you can effectively increase the size of the training set, which can help to prevent overfitting and improve the generalization of machine learning models.</p> <p>Example</p> <p></p> What is data cleaning ? <p>Data cleaning is a critical step in the data preprocessing pipeline that involves identifying and correcting errors,  inconsistencies, and missing or irrelevant data in a dataset. The goal of data cleaning is to prepare the data for  analysis or machine learning by ensuring that it is accurate, complete, and consistent.</p>"},{"location":"machine-learning/prerequisites/#data-cleaning-typically-involves-a-series-of-steps-which-may-include","title":"Data cleaning typically involves a series of steps, which may include:","text":""},{"location":"machine-learning/prerequisites/#missing-data-handling","title":"Missing data handling","text":"<p>If there are missing values in the dataset, data cleaning may involve imputing missing values  using techniques such as mean imputation, median imputation, or regression imputation.</p>"},{"location":"machine-learning/prerequisites/#outlier-detection-and-handling","title":"Outlier detection and handling","text":"<p>Outliers are data points that fall far outside the normal range of values in the  dataset. Data cleaning may involve detecting and handling outliers using techniques such as box plots, z-scores, or clustering.</p>"},{"location":"machine-learning/prerequisites/#data-formatting-and-type-conversion","title":"Data formatting and type conversion","text":"<p>Data cleaning may involve converting data types, such as converting categorical data to numerical data, or converting date formats to a standardized format.</p>"},{"location":"machine-learning/prerequisites/#removing-duplicates","title":"Removing duplicates","text":"<p>If there are duplicate records in the dataset, data cleaning may involve identifying and removing them to avoid biases in the analysis.</p>"},{"location":"machine-learning/prerequisites/#data-validation-and-verification","title":"Data validation and verification","text":"<p>Data cleaning may involve validating the data to ensure that it is accurate and  complete, such as cross-checking data against external sources or conducting manual spot-checks.</p>"},{"location":"machine-learning/resources/","title":"Some additional resources","text":"<ul> <li>https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf</li> <li>https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf</li> </ul>"},{"location":"machine-learning/tooling/","title":"Tooling we will use","text":""},{"location":"machine-learning/tooling/#language","title":"Language","text":"<p>Python</p>"},{"location":"machine-learning/tooling/#a-platform","title":"A platform","text":"<p>Google colab</p> <p>It's a cloud-based platform for developing and running machine learning models. It is a free service provided by Google  that allows users to write and run Python code in a Jupyter notebook environment, with access to powerful computing  resources and pre-installed libraries and frameworks for machine learning.</p> <p>Go to google colab</p>"},{"location":"machine-learning/tooling/#machine-learning-libraries","title":"Machine learning libraries","text":"<ul> <li>scikit-learn</li> <li>TensorFlow</li> <li>Keras</li> </ul> <p>These libraries provide pre-built functions and models for various machine learning tasks, making it easier to develop  machine learning models.</p>"},{"location":"machine-learning/tooling/#data-visualization-libraries","title":"Data visualization libraries","text":"<ul> <li>matplotlib </li> <li>seaborn</li> </ul>"},{"location":"machine-learning/tooling/#data-manipulation-libraries","title":"Data manipulation libraries","text":"<ul> <li>pandas</li> <li>numpy</li> </ul>"},{"location":"sorting-algorithm/bubble-sort/","title":"Bubble sort","text":""},{"location":"sorting-algorithm/bubble-sort/#bubble-sort","title":"Bubble sort","text":"<p>Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.</p> <p>Warning</p> <p>Bubble sort is not suitable to sort large datasets</p> <p>Implementation</p> GoPython <pre><code>func bubbleSort(integers []int) []int {\nnbElements := len(integers)\nfor i := 0; i &lt; nbElements-1; i++ {\nfor j := 0; j &lt; nbElements-i-1; j++ {\nif integers[j] &gt; integers[j+1] {\nintegers[j], integers[j+1] = integers[j+1], integers[j]\n}\n}\n}\nreturn integers\n}\n</code></pre> <pre><code>def bubble_sort():\npass\n</code></pre> <p>Time complexity</p> \\[ {O(n^2)} \\] <p>Space complexity \\({O(1)}\\)</p>"},{"location":"sorting-algorithm/insertion-sort/","title":"Insertion sort","text":""},{"location":"sorting-algorithm/insertion-sort/#insertion-sort","title":"Insertion sort","text":"<p>Insertion sort is a simple sorting algorithm that builds the final sorted array one item at a time. It iterates through an input list, compares adjacent elements and inserts the current element into the correct position in the sorted list.</p> <p>Warning</p> <p>Insertion sort is not suitable to sort large datasets</p> <p>Implementation</p> GoPython <pre><code>func insertionSort(integers []int) []int {\nnbElements := len(integers)\nfor i := 0; i &lt; nbElements; i++ {\nvalueToInsert := integers[i]\ncurrentPosition := i\nfor currentPosition &gt; 0 &amp;&amp; integers[currentPosition-1] &gt; valueToInsert {\nintegers[currentPosition] = integers[currentPosition-1]\ncurrentPosition = currentPosition - 1\n}\nintegers[currentPosition] = valueToInsert\n}\nreturn integers\n}\n</code></pre> <pre><code>def insertion_sort():\npass\n</code></pre> <p>Time complexity</p> <p>Space complexity</p>"},{"location":"sorting-algorithm/quick-sort/","title":"Quick sort","text":""},{"location":"sorting-algorithm/quick-sort/#quick-sort","title":"Quick sort","text":""},{"location":"sorting-algorithm/selection-sort/","title":"Selection sort","text":""},{"location":"sorting-algorithm/selection-sort/#selection-sort","title":"Selection sort","text":"<p>Selection sort is an in-place comparison sorting algorithm that divides the input list into two parts: the sublist of items already sorted, and the sublist of items remaining to be sorted. It finds the minimum element in the unsorted sublist and swaps it with the leftmost unsorted element, moving the sublist boundaries one element to the right.</p> <p>Warning</p> <p>Selection sort is not suitable to sort large datasets</p>"},{"location":"sorting-algorithm/selection-sort/#implementation","title":"Implementation","text":"GoPython <pre><code>func selectionSort(integers []int) []int {\nnbElements := len(integers)\nfor i := 0; i &lt; nbElements-1; i++ {\nminIndex := i\nfor j := i; j &lt; nbElements; j++ {\nif integers[j] &lt; integers[minIndex] {\nminIndex = j\n}\n}\nintegers[i], integers[minIndex] = integers[minIndex], integers[i]\n}\nreturn integers\n}\n</code></pre> <pre><code>def selection_sort():\npass\n</code></pre>"},{"location":"sorting-algorithm/selection-sort/#time-complexity","title":"Time complexity","text":""},{"location":"sorting-algorithm/selection-sort/#space-complexity","title":"Space complexity","text":"<p>Note</p> <p>Selection sort is useful when memory usage is a concern, as it is an in-place sorting algorithm that does not require additional memory. It is also useful when you only need to sort a small number of items, and performance is not a critical concern. Selection sort can be used when the list is partially sorted or when the order of equal elements is not important.</p>"}]}